{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ccc6bd-f52e-4c37-8743-bc0ff14f85bc",
   "metadata": {},
   "source": [
    "# Módulo 24 Tarefa 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8af521-bcb2-447c-bff9-1d322ce30af4",
   "metadata": {},
   "source": [
    "### 1. Cite 5 diferenças entre o Random Forest e o AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d77f85-4e03-44ae-9485-fc07dc1721d5",
   "metadata": {},
   "source": [
    "* Estratégia de Ensemble\n",
    "\n",
    "    - Random Forest: usa bagging (vários modelos treinados em subconjuntos de dados).\n",
    "\n",
    "    - AdaBoost: usa boosting (modelos treinados em sequência, cada um corrigindo erros do anterior).\n",
    "\n",
    "* Base Learner\n",
    "\n",
    "    - Random Forest: normalmente usa árvores de decisão completas (com poda).\n",
    "\n",
    "    - AdaBoost: usa árvores rasas (stumps) ou classificadores fracos.\n",
    "\n",
    "* Pesos nos dados\n",
    "\n",
    "    - Random Forest: todos os dados têm peso igual.\n",
    "\n",
    "    - AdaBoost: exemplos mal classificados recebem mais peso a cada iteração.\n",
    "\n",
    "* Combinação de modelos\n",
    "\n",
    "    - Random Forest: faz votação majoritária (classificação) ou média (regressão).\n",
    "\n",
    "    - AdaBoost: combina modelos com pesos baseados no desempenho de cada um.\n",
    "\n",
    "* Tendência a overfitting\n",
    "\n",
    "    - Random Forest: menos suscetível a overfitting.\n",
    "\n",
    "    - AdaBoost: pode sofrer mais overfitting em dados ruidosos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d85733-be3c-4e78-8f87-9a2615d67045",
   "metadata": {},
   "source": [
    "### 2. Acesse o link scikit-learn–adaboost , leia a explicação (traduza se for preciso) e crie um jupyter notebook contendo o exemplo do AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565e8a9f-d0df-4266-bb1a-59c54b3e4837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carrega o dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Cria o modelo\n",
    "clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Avalia o modelo\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c380679-843d-4676-8f9f-e95e495c1d5d",
   "metadata": {},
   "source": [
    "### 3. Cite cinco hiperparâmetros importantes no AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409aa2bc-df17-4796-b15c-a90188bd0445",
   "metadata": {},
   "source": [
    "- n_estimators: número de classificadores fracos.\n",
    "\n",
    "- learning_rate: taxa de aprendizado, controla peso dos classificadores.\n",
    "\n",
    "- base_estimator: modelo base (por padrão, DecisionTreeClassifier).\n",
    "\n",
    "- algorithm: “SAMME” (multi-class) ou “SAMME.R” (multi-class adaptado).\n",
    "\n",
    "- random_state: controla reprodutibilidade dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971794a-a51f-4dc6-94a2-29387742b809",
   "metadata": {},
   "source": [
    "### 4. Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94bb2c9b-a4f6-434e-83af-607671c4e186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Melhor score: 0.9549407114624506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid.best_params_)\n",
    "print(\"Melhor score:\", grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
